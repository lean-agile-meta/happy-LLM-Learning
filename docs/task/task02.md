# 第一章 NLP 基础概念

- 自然语言处理（Natural Language Processing，NLP）
  - 使计算机能够理解和处理人类语言，实现人机之间的自然交流。
  - 信息技术飞速发展，文本数据已成日常生活不可或缺的一部分
  - NLP 技术的进步为我们从海量文本中提取有用信息、理解语言的深层含义提供了强有力的工具。
    - 早期的基于规则的方法
    - 后来的统计学习方法
    - 当前深度学习技术
    - 文本表示作为 NLP 的核心技术之一

## 1.1 什么是 NLP

- 核心任务是通过计算机程序来模拟人类对语言的认知和使用过程
- NLP 技术使得计算机能够执行各种复杂的语言处理任务
  - 中文分词
  - 子词切分
  - 词性标注
  - 文本分类
  - 实体识别
  - 关系抽取
  - 文本摘要
  - 机器翻译
  - 自动问答等
  - 这些任务不仅要求计算机能够识别和处理语言的表层结构
  - 更重要的是可以理解语言背后的深层含义，包括语义、语境、情感和文化等方面的复杂因素。
  - 面临着诸多挑战
    - 处理歧义性
  - 理解抽象概念
  - 处理隐喻和讽刺等。
- NLP 技术的发展，使其在机器翻译、情感分析、实体识别和文本摘要等任务上取得了显著成就。

## 1.2 NLP 发展历程

- 早期探索（1940 年代 - 1960 年代）规则基础方法
  - 1950 年，艾伦·图灵提出了图灵测试。
    - 如果一台机器可以通过使用打字机成为对话的一部分，并且能够完全模仿人类，没有明显的差异，那么机器可以被认为是能够思考的。
  - 判断机器是否能够展现出与人类不可区分的智能行为的测试
  - 诺姆·乔姆斯基提出了生成语法理论
    - 对理解机器翻译的工作方式产生了重要影响
  - 主要依赖字典查找和基本的词序规则来进行翻译，效果并不理想。
- 符号主义与统计方法（1970 年代 - 1990 年代）统计学习方法
  - 逻辑基础的范式和自然语言理解
  - 分为符号主义（或规则基础）和统计方法两大阵营。
    - 符号主义研究者关注于形式语言和生成语法
  - 统计方法的研究者更加关注于统计和概率方法。
- 机器学习与深度学习（2000 年代至今）深度学习技术
  - 深度学习模型
    - 循环神经网络（Recurrent Neural Network，RNN）
  - 长短时记忆网络（Long Short-Term Memory，LSTM）
  - 注意力机制等技术
  - 2013 年 Word2Vec 模型
    - 词向量表示
  - 为 NLP 任务提供了更加有效的文本表示方法。
  - 2018 年 BERT 模型
    - 预训练语言模型
  - 基于 Transformer 的模型
    - 通过训练巨大参数的模型，能够生成高质量的文本，甚至在某些情况下可以与人类写作相媲美。
  - 如 GPT-3

## 1.3 NLP 任务

- 核心任务构成了 NLP 领域的基础，涵盖了从文本的基本处理到复杂的语义理解和生成的各个方面。

### 1.3.1 中文分词

- 中文分词（Chinese Word Segmentation, CWS）
  - 将连续的中文文本切分成有意义的词汇序列。
  - 词与词之间没有像英文那样的明显分隔（如空格），所以无法直接通过空格来确定词的边界。
  - 正确的分词结果对于后续的词性标注、实体识别、句法分析等任务至关重要。
  - 分词不准确，将直接影响到整个文本处理流程的效果。

### 1.3.2 子词切分

- 子词切分（Subword Segmentation）
  - 将词汇进一步分解为更小的单位，即子词。
  - 特别适用于处理词汇稀疏问题
    - 当遇到罕见词或未见过的新词时，能够通过已知的子词单位来理解或生成这些词汇。
  - 尤为重要
    - 在处理那些拼写复杂、合成词多的语言（如德语）中
  - 在预训练语言模型（如 BERT、GPT 系列）中
  - 子词切分的方法
    - Byte Pair Encoding (BPE)
  - WordPiece
  - Unigram
  - SentencePiece 等
  - 方法的基本思想是将单词分解成更小的、频繁出现的片段
    - 片段可以是单个字符、字符组合或者词根和词缀。
  - 示例：
    - unhappiness
      - “un” 前缀“un”表示否定
    - “happi” “happi”是“happy”的词根变体，表示幸福
    - “ness” 名词后缀，表示状态。
    - 即使模型从未见过“unhappiness”这个完整的单词，它也可以通过这些已知的子词来理解其大致意思为“不幸福的状态”。

### 1.3.3 词性标注

- 词性标注（Part-of-Speech Tagging，POS Tagging）
  - 对于理解句子结构、进行句法分析、语义角色标注等高级 NLP 任务至关重要。
    - 通过词性标注，计算机可以更好地理解文本的含义，进而进行信息提取、情感分析、机器翻译等更复杂的处理。
  - 词性标注通常依赖于机器学习模型
    - 这些模型通过学习大量的标注数据来预测新句子中每个单词的词性。
    - 隐马尔可夫模型（Hidden Markov Model，HMM）
    - 是一种概率模型，广泛应用于时间序列分析、自然语言处理、语音识别、基因序列分析等领域。
    - 它描述了一个系统在隐藏状态之间以马尔可夫链方式转移，同时系统会生成可观测的输出。
    - 马尔可夫，马尔可夫性、马尔可夫链、马尔可夫链计算等 HMM 的数学基础知识
    - 隐马尔可夫模型的假设、图结构、联合概率分布等马尔可夫模型的原理
    - 马尔可夫模型的前向算法、维特比算法
      - 贝叶斯模型 Bayes
  - 条件随机场（Conditional Random Field，CRF）
    - 是一种判别式的概率图模型，在序列标注任务中有着广泛的应用。相比隐马尔可夫模型(HMM)，CRF 能够克服标记偏置问题，并且可以引入更丰富的特征。
    - 条件随机场 CRF 与深度学习结合，产生了 BiLSTM-CRF、BiLSTM-CNN-CRF 等模型，在中文分词、命名实体识别、词性标注也取得不错的效果。
      - 条件随机场 CRF 与 Attention 机制结合，又发展成了 Transformer-CRF、BERT-BiLSTM-CRF 等模型，使中文分词、命名实体识别、词性标注效果又有显著提高。
  - 基于深度学习
    - 循环神经网络 RNN
    - 长短时记忆网络 LSTM 等。
  - 为文本中的每个单词分配一个词性标签，如名词、动词、形容词等。
  - 这个过程通常基于预先定义的词性标签集
    - 如英语中的常见标签有名词（Noun，N）、动词（Verb，V）、形容词（Adjective，Adj）等。

### 1.3.4 文本分类

- （Text Classification）
- 涉及到将给定的文本自动分配到一个或多个预定义的类别中。
- 广泛应用于各种场景，
  - 包括但不限于情感分析、垃圾邮件检测、新闻分类、主题识别等。
- 文本分类任务的成功关键在于选择合适的特征表示和分类算法，以及拥有高质量的训练数据。

### 1.3.5 实体识别

- 实体识别（Named Entity Recognition, NER），也称为命名实体识别

### 1.3.6 关系抽取

### 1.3.7 文本摘要

### 1.3.8 机器翻译

### 1.3.9 自动问答
